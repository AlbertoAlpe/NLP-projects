{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Similarity with WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import wordnet as wn \n",
    "import numpy as np \n",
    "import os \n",
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet', quiet=True) \n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "depth_max = max(max(len(hyp_path) for hyp_path in ss.hypernym_paths()) for ss in wn.all_synsets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni usate per calcolare la similarità\n",
    "Maximum Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_similarity(term1, term2, similarity_function): \n",
    "    synsets1 = wn.synsets(term1) \n",
    "    synsets2 = wn.synsets(term2)\n",
    "     \n",
    "    max_sim = 0 \n",
    "     \n",
    "    for syn1 in synsets1: \n",
    "        for syn2 in synsets2: \n",
    "            sim = similarity_function(syn1, syn2) \n",
    "            if sim > max_sim: \n",
    "                max_sim = sim \n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo della similarità di Wu-Palmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wu_palmer_similarity(syn1, syn2): \n",
    "    lcs_candidates = syn1.lowest_common_hypernyms(syn2) \n",
    "    if not lcs_candidates: \n",
    "        return 0 \n",
    "    lcs = lcs_candidates[0] \n",
    "    depth_lcs = lcs.max_depth() \n",
    "    depth_syn1 = syn1.max_depth() \n",
    "    depth_syn2 = syn2.max_depth() \n",
    "    return (2 * depth_lcs) / (depth_syn1 + depth_syn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo della Shortest path similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_similarity(syn1, syn2):\n",
    "    path_length = syn1.shortest_path_distance(syn2)\n",
    "    if path_length is None:\n",
    "        return 0\n",
    "    return 2 * depth_max - path_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo della similarità di Leacock&Chodorow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leacock_chodorow_similarity(syn1, syn2):\n",
    "    if depth_max == 0: \n",
    "        return 0 \n",
    "    path_length = syn1.shortest_path_distance(syn2) \n",
    "    if path_length is None or path_length == 0:\n",
    "        return 0 \n",
    "    return -np.log((path_length) / (2 * depth_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indici di correlazione di Spearman e Pearson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations(list, similarity_function): \n",
    "    similarities = [] \n",
    "    human_ratings = [float(row[2]) / 10 for row in list] \n",
    "     \n",
    "    for row in list: \n",
    "        sim = max_similarity(row[0], row[1], similarity_function) \n",
    "        similarities.append(sim) \n",
    "         \n",
    "    spearman_corr = spearmanr(human_ratings, similarities) \n",
    "    pearson_corr = pearsonr(human_ratings, similarities) \n",
    "    #print(human_ratings) \n",
    "    #print(similarities) \n",
    "    return spearman_corr, pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo delle metriche di similarità + indici di correlazione\n",
    "Lettura dei dati da 'WordSim353.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "file_name = 'WordSim353.csv'\n",
    " \n",
    "file_path = os.path.join(current_dir, 'cc', file_name)\n",
    "\n",
    "with open(file_name, 'r', encoding='utf-8') as train: \n",
    "   righe = train.readlines()[1:] \n",
    " \n",
    "combo_parole = [] \n",
    " \n",
    "for riga in righe: \n",
    "    riga = riga.strip().split(',') \n",
    "    combo_parole.append([riga[0], riga[1], riga[2]]) \n",
    " \n",
    "print(combo_parole)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo e stampa dei risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_wup, pearson_wup = calculate_correlations(combo_parole, wu_palmer_similarity) \n",
    "spearman_path, pearson_path = calculate_correlations(combo_parole, shortest_path_similarity) \n",
    "spearman_lch, pearson_lch = calculate_correlations(combo_parole, leacock_chodorow_similarity)\n",
    "\n",
    "print(f\"Wu & Palmer - Spearman: {spearman_wup}, Pearson: {pearson_wup}\") \n",
    "print(f\"Shortest Path - Spearman: {spearman_path}, Pearson: {pearson_path}\") \n",
    "print(f\"Leacock & Chodorow - Spearman: {spearman_lch}, Pearson: {pearson_lch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[S1: {}] {}\\n'.format(s1, s1.definition()))\n",
    "print('[S1: {}] {}\\n'.format(s2, s2.definition()))\n",
    "\n",
    "print('wup_similarity({}, {}) = {}'.format(s1, s2, s1.wup_similarity(s2)))\n",
    "print('lch_similarity({}, {}) = {}'.format(s1, s2, s1.lch_similarity(s2)))\n",
    "print('path_similarity({}, {}) = {}'.format(s1, s2, s1.path_similarity(s2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import semcor\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per assicurarsi di avere i corpora necessari\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('semcor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semcor\n",
    "Estrazione di 50 frasi casuali "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_from_semcor(n):\n",
    "    sentences = []\n",
    "    target_words = []\n",
    "    annotated_senses = []\n",
    "\n",
    "    for i in range(n):\n",
    "        sentence = semcor.tagged_sents(tag='both')[i]\n",
    "        words = []\n",
    "        word = None\n",
    "        sense = None\n",
    "\n",
    "        for w in sentence:\n",
    "            if isinstance(w, nltk.Tree) and w.label().startswith('NN'):\n",
    "                word = w.leaves()[0]\n",
    "                sense = w.label()\n",
    "                if sense is not None:\n",
    "                    sense = wn.synset(sense)\n",
    "                break\n",
    "            else:\n",
    "                words.append(w[0])\n",
    "        \n",
    "        if word and sense:\n",
    "            sentences.append(words)\n",
    "            target_words.append(word)\n",
    "            annotated_senses.append(sense)\n",
    "    \n",
    "    return sentences, target_words, annotated_senses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesk\n",
    "Implementazione dell'algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk_algorithm(context_sentence, ambiguous_word):\n",
    "    max_overlap = 0\n",
    "    best_sense = None\n",
    "    context = set(nltk.word_tokenize(context_sentence))\n",
    "    \n",
    "    for sense in wn.synsets(ambiguous_word, pos=wn.NOUN):\n",
    "        signature = set(nltk.word_tokenize(sense.definition()))\n",
    "        for example in sense.examples():\n",
    "            signature.update(nltk.word_tokenize(example))\n",
    "        \n",
    "        overlap = len(context.intersection(signature))\n",
    "        \n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "    \n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dell'algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lesk(sentences, target_words, annotated_senses):\n",
    "    correct = 0\n",
    "    for i in range(len(sentences)):\n",
    "        context_sentence = ' '.join(word for word in sentences[i])\n",
    "        ambiguous_word = target_words[i]\n",
    "        predicted_sense = lesk_algorithm(context_sentence, ambiguous_word)\n",
    "        actual_sense = annotated_senses[i]\n",
    "        \n",
    "        if predicted_sense == actual_sense:\n",
    "            correct += 1\n",
    "    return correct / len(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicazione dell'algoritmo a frasi estratte casualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_evaluation(n, iterations):\n",
    "    accuracies = []\n",
    "    for _ in range(iterations):\n",
    "        sentences, target_words, annotated_senses = extract_sentences_from_semcor(n)\n",
    "        accuracy = evaluate_lesk(sentences, target_words, annotated_senses)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return sum(accuracies) / len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguire l'algoritmo\n",
    "num_sentences = 50\n",
    "iterations = 10\n",
    "average_accuracy = randomize_evaluation(num_sentences, iterations)\n",
    "print(f\"Average Accuracy over {iterations} iterations: {average_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

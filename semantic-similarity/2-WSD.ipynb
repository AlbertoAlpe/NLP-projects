{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import re\n",
    "from nltk import MWETokenizer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import semcor\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estrazione stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "TOTAL_SEMCOR_SENTENCES = len(semcor.tagged_sents(tag = 'sem'))\n",
    "\n",
    "multi_word_expressions = [x for x in wn.all_lemma_names() if '_' in x]\n",
    "multi_word_expressions = [tuple(x.split('_')) for x in multi_word_expressions]\n",
    "mwe_tokenizer = MWETokenizer(multi_word_expressions, separator=' ')\n",
    "word_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semcor\n",
    "Estrazione di 50 frasi casuali "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(txt):\n",
    "    \"\"\"Preprocessa il testo rimuovendo punteggiatura, stop words, ecc.\"\"\"\n",
    "    txt = re.sub(r'[^\\w\\s]',' ',txt)\n",
    "    txt = txt.lower()\n",
    "    txt = mwe_tokenizer.tokenize(txt.split())\n",
    "    txt = [word_lemmatizer.lemmatize(token) for token in txt]\n",
    "    txt = [w for w in txt if not w in stop_words]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesk\n",
    "Implementazione dell'algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_lesk_algorithm(word, pos, context):\n",
    "    \"\"\"Implementazione semplificata dell'algoritmo Lesk.\"\"\"\n",
    "    word = wn.morphy(word) if wn.morphy(word) is not None else word\n",
    "    best_synset = wn.synsets(word)[0] if len(wn.synsets(word)) > 0 else None #wordnet mette in ordine i sysnet basandosi sulla frequenza\n",
    "    max_overlap = 0\n",
    "\n",
    "    for synset in wn.synsets(word, pos=pos):\n",
    "        signature = set(preprocess_text(synset.definition())).union(set(preprocess_text(' '.join(synset.examples()))))\n",
    "        overlap = len(context.intersection(signature))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_synset = synset\n",
    "    \n",
    "    return best_synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dell'algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_algorithm():\n",
    "    \"\"\"Valuta l'accuratezza dell'algoritmo su un campione di 50 frasi di SemCor.\"\"\"\n",
    "    tagged_sentences = semcor.tagged_sents(tag = 'sem')[:100]\n",
    "    plain_sentences = semcor.sents()[:100]\n",
    "    np.random.seed()\n",
    "    selected_indices = np.random.permutation(len(tagged_sentences))[:50]\n",
    "\n",
    "    sample_tagged_sentences = [tagged_sentences[i] for i in selected_indices]\n",
    "    sample_plain_sentences = [plain_sentences[i] for i in selected_indices]\n",
    "    total_sentences = len(sample_plain_sentences)\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for i, sentence in enumerate(sample_plain_sentences):\n",
    "        sentence_without_stopwords = [w for w in sentence if not w in stop_words and w.isalpha()]\n",
    "        random_word = random.choice(sentence_without_stopwords)\n",
    "        actual_synset = None\n",
    "        predicted_synset = None\n",
    "\n",
    "        found = False\n",
    "        for j, cell in enumerate(sample_tagged_sentences[i]):\n",
    "            if not found:\n",
    "                if random_word in cell[0]:\n",
    "                    label = cell.label() if isinstance(cell, nltk.tree.Tree) else None\n",
    "\n",
    "                    if label and hasattr(label, 'synset'):\n",
    "                        actual_synset = label.synset()\n",
    "                        pos = actual_synset.pos()\n",
    "                        context = set(sentence)\n",
    "                        predicted_synset = basic_lesk_algorithm(random_word, pos, context)\n",
    "                        found = True\n",
    "        \n",
    "        if actual_synset is not None and predicted_synset is not None:\n",
    "            correct_predictions += predicted_synset == actual_synset\n",
    "        else:\n",
    "            total_sentences -= 1\n",
    "                \n",
    "    accuracy = correct_predictions / total_sentences\n",
    "    print('accuracy: ', accuracy)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicazione dell'algoritmo a frasi estratte casualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.4090909090909091\n",
      "accuracy:  0.43243243243243246\n",
      "accuracy:  0.3695652173913043\n",
      "accuracy:  0.43478260869565216\n",
      "accuracy:  0.5238095238095238\n",
      "accuracy:  0.45652173913043476\n",
      "accuracy:  0.36585365853658536\n",
      "accuracy:  0.5\n",
      "accuracy:  0.38095238095238093\n",
      "accuracy:  0.4666666666666667\n",
      "\n",
      "\n",
      "mean accuracy:  0.433967513670589\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(10):\n",
    "    accuracies.append(evaluate_algorithm())\n",
    "\n",
    "print('\\n')\n",
    "print('mean accuracy: ', np.mean(accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
